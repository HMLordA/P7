#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass report
\begin_preamble
\usepackage[english]{babel}
\usepackage{amsfonts}
% Bonus
\usepackage{dsfont}


\newtheorem{theorem}{}\newcommand{\EE}{\mathbb{E}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\bslash}{\texttt{\symbol{92}}}
\newcommand{\Tau}{\mathrm{T}}

\title{Unconstrained Recursive Importance Sampling}
\author{Jean-Christophe DIETRICH and Nazar KOSTYUCHYK}
\end_preamble
\use_default_options true
\begin_modules
theorems-std
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-1
\fontencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 2
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Monte-Carlo Project : 
\begin_inset Newline newline
\end_inset

Unconstrained Recursive Importance Sampling
\end_layout

\begin_layout Author
Jean-Christophe DIETRICH & Nazar KOSTYUCHYK
\end_layout

\begin_layout Date
Master M2MO - April 2016
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Standard
An unconstrained stochastic approximation method of finding the optimal
 measure change (in an a priori parametric family) for Monte Carlo simulations,
 has been proposed by Gilles Pages and Vincent Lemaire in 2009.
 The main idea was to improve Arouna's previous work which consisted to
 use a projected Robbins-Monro procedure to select the parameter minimizing
 the variance, in a multidimensional Gaussian framework.
\end_layout

\begin_layout Standard
In the approach developed by the authors, this parameter (scalar or process)
 is selected by a classical Robbins-Monro procedure without projection or
 truncation, allowing the method to be unconstrained.
 In order to obtain this algorithm they intensively use the regularity of
 the density of the law without assuming smoothness of the payoff.
 They also prove the convergence for a large class of multidimensional distribut
ions and diffusion processes.
\end_layout

\begin_layout Standard
In this project we will implement this algorithm and illustrate its effectivenes
s and disadvantages on a set of payoffs and processes.
 In order to make general conclusions, we price different payoff types (differen
t maturities, multi-underlying, path-dependent), having or not closed formulas.
\end_layout

\begin_layout Section
Motivation
\end_layout

\begin_layout Standard
The basic problem in numerical probability is to optimize by a Monte Carlo
 simulation the computation of a real quantity m known by a probabilistic
 representation 
\begin_inset Formula 
\[
m=\EE[F(X)]
\]

\end_inset

where 
\begin_inset Formula $X:(\Omega,A,\PP)\mapsto(\RR^{d},|.|_{\RR^{d}})$
\end_inset

 is a random vector and 
\begin_inset Formula $F:\RR^{d}\mapsto\RR$
\end_inset

 is a Borel function (
\begin_inset Formula $F(X)$
\end_inset

 is square integrable).
\end_layout

\begin_layout Standard
We assume that X has an absolutely continuous distribution 
\begin_inset Formula $\PP_{X}(dx)=p(x)\lambda_{d}(dx)$
\end_inset

 and that 
\begin_inset Formula $F\in L^{2}(\PP_{X})$
\end_inset

 with 
\begin_inset Formula $\PP(F(X)\neq0)>0$
\end_inset

.
 Furthermore we assume that the probability density p is everywhere positive
 on 
\begin_inset Formula $\RR^{d}$
\end_inset

.
\end_layout

\begin_layout Standard
The importance sampling applied to a parametrized family of distributions
 is the following: consider the family of absolutely continuous probability
 distributions 
\begin_inset Formula $\pi_{\theta}(dx)=p_{\theta}(x)dx$
\end_inset

, 
\begin_inset Formula $\theta\in\Theta$
\end_inset

(we assume that 
\begin_inset Formula $\Theta=\RR^{q}$
\end_inset

), such that 
\begin_inset Formula $p_{\theta}(x)>0$
\end_inset

 
\begin_inset Formula $\lambda_{d}(dx)$
\end_inset

 a.e.
 Then for any 
\begin_inset Formula $\RR^{q}$
\end_inset

-valued random variable 
\begin_inset Formula $X(\theta)$
\end_inset

 with distribution 
\begin_inset Formula $\pi_{\theta}$
\end_inset

, we have by change of probability: 
\begin_inset Formula 
\begin{equation}
\EE[F(X)]=\EE\left[F(X^{\theta})\frac{p(X^{\theta})}{p_{\theta}(X^{\theta})}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We are looking for the variable 
\begin_inset Formula $X^{\theta}$
\end_inset

 with the minimal variance i.e.
 (as they have the same mean) the one with the lowest quadratic norm : 
\begin_inset Formula 
\begin{equation}
V(\theta)=\EE\left[F^{2}(X^{\theta})\right]=\EE\left[F(X^{\theta})^{2}\frac{p^{2}(X^{\theta})}{p_{\theta}^{2}(X^{\theta})}\right]=\EE\left[F^{2}(X)\frac{p(X)}{p_{\theta}(X)}\right]
\end{equation}

\end_inset

the last equality given by another change of variable.
 We therefore want to find 
\begin_inset Formula $\theta^{*}$
\end_inset

solving the minimization problem 
\begin_inset Formula 
\[
\theta^{*}=argmin_{\theta\in\RR^{^{q}}}V(\theta)
\]

\end_inset


\end_layout

\begin_layout Standard
It is possible to show that under certain conditions on the convexity and
 growth of the density 
\begin_inset Formula $p_{\theta}$
\end_inset

, 
\begin_inset Formula $\theta^{*}$
\end_inset

is unique.
 We can therefore use a minimization procedure like the Robbins-Monro or
 Newton-Raphson algorithms.
\end_layout

\begin_layout Section
A benchmark : stochastic Newton-Raphson algorithm
\end_layout

\begin_layout Standard
For more clarity we consider in this section the d-dimensional independent
 gaussian case.
 Let us consider 
\begin_inset Formula $X\sim N(0,\,I_{d})$
\end_inset

.
\end_layout

\begin_layout Standard
For 
\begin_inset Formula $\theta\in\RR^{d}$
\end_inset

 and 
\begin_inset Formula $F$
\end_inset

 as before, we have 
\begin_inset Formula 
\[
\EE[F(X)]=\EE\left[F(X+\theta)e^{-\theta.G-\frac{|\theta|^{2}}{2}}\right]
\]

\end_inset

 and 
\begin_inset Formula 
\[
Var[F(X)]=V(\theta)-\EE[F(X)]^{2}
\]

\end_inset

 where 
\begin_inset Formula 
\[
V(\theta)=\EE\left[F^{2}(X)e^{-\theta.G+\frac{|\theta|^{2}}{2}}\right]
\]

\end_inset

for which we are looking for 
\begin_inset Formula $\theta^{*}=Argmin_{\theta}V(\theta)$
\end_inset

.
 By formal differentiation we have
\begin_inset Formula 
\[
\nabla V(\theta)=\EE\left[F^{2}(X)e^{-\theta.G+\frac{|\theta|^{2}}{2}}(\theta-G)\right]
\]

\end_inset

and 
\begin_inset Formula 
\[
\nabla^{2}V(\theta)=\EE\left[F^{2}(X)e^{-\theta.G+\frac{|\theta|^{2}}{2}}(I_{d}+(\theta-G)(\theta-G)^{T})\right]
\]

\end_inset

We can show that these quantities can be approached well by their empirical
 estimators, noted 
\begin_inset Formula $\nabla_{M}V(\theta)$
\end_inset

 and 
\begin_inset Formula $\nabla^{2}V(\theta)$
\end_inset

 for a large integer 
\begin_inset Formula $M>0$
\end_inset

.
 
\begin_inset Formula $\theta^{*}$
\end_inset

can therefore be approached by 
\begin_inset Formula $\theta_{M}^{*}$
\end_inset

, the unique solution of the equation 
\begin_inset Formula $\nabla V_{M}(\theta)=0$
\end_inset

.
 This leads to the following stochastic Newton-Raphson algorithm :
\end_layout

\begin_layout Itemize
Choose 
\begin_inset Formula $\theta_{0}\in\RR^{d}$
\end_inset

.
 
\begin_inset Formula $p=0$
\end_inset

.
 
\begin_inset Formula $\epsilon>0$
\end_inset

 small.
\end_layout

\begin_layout Itemize
while 
\begin_inset Formula $|\nabla_{M}V(\theta_{p})|>\epsilon|$
\end_inset

 do
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\theta_{p+1}=\theta_{p}-(\nabla_{M}^{2}V(\theta_{p}))^{-1}\nabla_{M}V(\theta_{p})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $p=p+1$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
We finally approximate 
\begin_inset Formula $\EE[F(X)]$
\end_inset

 by 
\begin_inset Formula 
\[
E_{M}(\theta_{M}^{*})=\frac{1}{M}{\displaystyle \sum_{i=1}^{M}f(G^{i}+\theta_{M}^{*})e^{-\theta_{M}^{*}.G-\frac{|\theta_{M}^{*}|^{2}}{2}}}
\]

\end_inset


\end_layout

\begin_layout Section
An unconstrained Robbins-Monro approach
\end_layout

\begin_layout Subsection
Robbins-Monro principle
\end_layout

\begin_layout Standard
We are looking for the unique minimum 
\begin_inset Formula $\theta^{*}=argmin_{\theta\in\RR^{^{q}}}V(\theta)$
\end_inset

.
 As we have no 
\shape italic
a priori
\shape default
 knowledge about the regularity of 
\begin_inset Formula $F$
\end_inset

, as in previous section we can formally differentiate 
\begin_inset Formula $(2)$
\end_inset

 :
\begin_inset Formula 
\[
\nabla V(\theta)=\EE\left[F^{2}(X)\frac{p(X)}{p_{\theta}(X)}\frac{\nabla_{\theta}p_{\theta}(X)}{p_{\theta}(X)}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
We then note the function 
\begin_inset Formula $H(\theta,X)=F^{2}(X)\frac{p(X)}{p_{\theta}(X)}\frac{\nabla_{\theta}p_{\theta}(X)}{p_{\theta}(X)}$
\end_inset

, which gives us 
\begin_inset Formula $\nabla V(\theta)=\EE\left[H(\theta,X)\right]$
\end_inset

.
\end_layout

\begin_layout Standard
The Robbins-Monro algorithm then consists in finding 
\begin_inset Formula $\theta^{*}$
\end_inset

 as the convergence point of the iterative procedure:
\begin_inset Formula 
\[
\theta_{n+1}=\theta_{n}-\gamma_{n+1}H(\theta_{n},X_{n+1})
\]

\end_inset

 with 
\begin_inset Formula $(\gamma_{n})_{n\geq0}$
\end_inset

 a step sequence (appropriately) decreasing to 0 and 
\begin_inset Formula $(X_{n})_{n\geq0}$
\end_inset

 a sequence of i.i.d random variables with the same law as 
\begin_inset Formula $X$
\end_inset

.
 
\end_layout

\begin_layout Standard
To converge to 
\begin_inset Formula $\theta^{*}$
\end_inset

, this procedure requires several assumptions, one of them being quite restricti
ve : the sub-linear growth assumption in quadratic mean (NEC : Non-Explosion
 Condition)
\begin_inset Formula 
\[
\forall\theta\in\RR^{d},\hphantom{}||H(\theta,X)||_{2}\leq C(1+|\theta|)
\]

\end_inset

In practice, this condition is almost never satisfied in our framework (due
 to the behaviour of 
\begin_inset Formula $\frac{p(x)}{p_{\theta}(x)}$
\end_inset

 as 
\begin_inset Formula $\theta$
\end_inset

 goes to infinity).
 There is therefore a need of additional work to derive a extended version
 of this algorithm, which converge to 
\begin_inset Formula $\theta^{*}$
\end_inset

 a.s.
 The authors provide a method in their article to tackle this problem.
\end_layout

\begin_layout Subsection
Controlling NEC
\end_layout

\begin_layout Standard
The authors introduce a third change of probability to control the term
\begin_inset Formula $\frac{p(x)}{p_{\theta}(x)}$
\end_inset

.
 We can find a positive density 
\begin_inset Formula $q_{\theta}$
\end_inset

, so we have 
\begin_inset Formula 
\[
\nabla V(\theta)=\EE\left[F^{2}(X)\frac{p(X)}{p_{\theta}(X)}\frac{\nabla_{\theta}p_{\theta}(X)}{p_{\theta}(X)}\right]=\EE\left[F^{2}(\widetilde{X}^{(\theta)})\frac{p(\widetilde{X}^{(\theta)})}{p_{\theta}(\widetilde{X}^{(\theta)})q_{\theta}(\widetilde{X}^{(\theta)})}\frac{\nabla_{\theta}p_{\theta}(\widetilde{X}^{(\theta)})}{p_{\theta}(\widetilde{X}^{(\theta)})}\right]=\EE\left[\tilde{H}(\theta,\widetilde{X}^{(\theta)})\right]
\]

\end_inset

where 
\begin_inset Formula $\widetilde{X}^{(\theta)}\sim q_{\theta}(x)dx$
\end_inset

 and where 
\begin_inset Formula $\tilde{H}(\theta,\widetilde{X}^{(\theta)})=F^{2}(\widetilde{X}^{(\theta)})\frac{p(\widetilde{X}^{(\theta)})}{p_{\theta}(\widetilde{X}^{(\theta)})q_{\theta}(\widetilde{X}^{(\theta)})}\frac{\nabla_{\theta}p_{\theta}\widetilde{X}^{(\theta)})}{p_{\theta}(\widetilde{X}^{(\theta)})}$
\end_inset

.
\end_layout

\begin_layout Standard
The role of the density 
\begin_inset Formula $q_{\theta}$
\end_inset

 will be to control the term 
\begin_inset Formula $\frac{p(\widetilde{X}^{(\theta)})}{p_{\theta}(\widetilde{X}^{(\theta)})q_{\theta}(\widetilde{X}^{(\theta)})}$
\end_inset

 by a deterministic quantity depending of 
\begin_inset Formula $\theta$
\end_inset

 only.
 Under this assumption the theorem of the following section will apply.
\end_layout

\begin_layout Subsection
Extended Robbins-Monro theorem
\end_layout

\begin_layout Theorem
:
\begin_inset Argument 1
status open

\begin_layout Plain Layout
(Extended Robbins-Monro Theorem)
\end_layout

\end_inset

 Let H : 
\begin_inset Formula $\RR^{q}\times\RR^{d}\mapsto\RR^{d}$
\end_inset

 a Borel function and 
\begin_inset Formula $X$
\end_inset

 an 
\begin_inset Formula $\RR^{d}$
\end_inset

-valued random vector such that 
\begin_inset Formula $\EE[|H(\theta,X)|]<\infty$
\end_inset

 for every 
\begin_inset Formula $\theta\in\RR^{d}$
\end_inset

.
 Then set 
\begin_inset Formula 
\begin{equation}
\forall\theta\in\RR^{d},\quad h(\theta)=[H(\theta,X)]
\end{equation}

\end_inset

Suppose that the function h is continuous and that 
\begin_inset Formula $T={h=0}$
\end_inset

 satisfies 
\begin_inset Formula 
\begin{equation}
\forall\theta\in\RR^{d}\bslash\Tau^{*},\ \forall\theta^{*}\in\Tau^{*}\quad\left<\theta-\theta^{*},h(\theta)\right>>0
\end{equation}

\end_inset

Let 
\begin_inset Formula $\gamma=(\gamma_{n})_{n\geq1}$
\end_inset

 be a sequence of gain parameters satisfying 
\begin_inset Formula 
\begin{equation}
\sum\limits _{\substack{n\geq1}
}^{}{\gamma_{n}}=+\infty\quad and\quad\sum\limits _{\substack{n\geq1}
}^{}{\gamma_{n}^{2}}<+\infty
\end{equation}

\end_inset

Suppose that 
\begin_inset Formula 
\begin{equation}
\forall\theta\in\RR^{d},\quad\EE[|H(\theta,X)|^{2}]<C(1+|\theta|^{2})
\end{equation}

\end_inset

Let 
\begin_inset Formula $(X_{n})_{n\geq1}$
\end_inset

 be an 
\begin_inset Formula $i.i.d.$
\end_inset

 sequence of random vectors having the distribution of 
\begin_inset Formula $X$
\end_inset

, a random vector 
\begin_inset Formula $\theta_{0}$
\end_inset

, independent of 
\begin_inset Formula $(X_{n})_{n\geq1}$
\end_inset

 satisfying 
\begin_inset Formula $\EE[|H(\theta_{0}|^{2}]<+\infty$
\end_inset

, all defined on the same probability space 
\begin_inset Formula $(\Omega,A,\PP)$
\end_inset

.Then, the recursive procedure defined by 
\begin_inset Formula 
\begin{equation}
\theta_{n}=\theta_{n-1}-\gamma_{n+1}H(\theta_{n},X_{n+1}),\quad n\geq1
\end{equation}

\end_inset

satisfies: 
\begin_inset Formula 
\begin{equation}
\exists\theta_{\infty}:(\Omega,A)\mapsto\Tau^{*},\ \theta_{\infty}\in L^{2}(\PP),\quad such\ that\ \theta_{n}\xmapsto{a.s}\theta_{\infty}
\end{equation}

\end_inset

The convergence also holds in 
\begin_inset Formula $L^{p}(\PP)$
\end_inset

, 
\begin_inset Formula $p\in(0,2)$
\end_inset

.
\end_layout

\begin_layout Subsection
Unconstraint extension
\end_layout

\begin_layout Standard
We note that with the change of probability introduced in subsection 1.3.2,
 the parameter 
\begin_inset Formula $\theta$
\end_inset

 is now inside the function 
\begin_inset Formula $F$
\end_inset

.
 Therefore if we have a control on 
\begin_inset Formula $F$
\end_inset

 as 
\begin_inset Formula $|x|$
\end_inset

 goes to infinity, the (NEC) hypothesis is verified and so we have a converging
 Robbins-Monro method without explosion or risk of freezing due to a to
 a too strong 
\begin_inset Formula $(\gamma_{n})$
\end_inset

 sequence.
 If 
\begin_inset Formula $F$
\end_inset

 is not bounded, we need another control property on 
\begin_inset Formula $F$
\end_inset

.
 On this purpose, the authors show the following result when considering
 importance sampling by mean translation i.e.
 
\begin_inset Formula $\forall x\in\RR^{d},\quad p_{\theta}(x)=p(x-\theta)$
\end_inset

.
 We can also consider 
\begin_inset Formula $\forall x\in\RR^{d},\quad q_{\theta}(x)=\frac{p^{2}(x)}{p(x-\theta)}=p(x+\theta)$
\end_inset

.
\end_layout

\begin_layout Standard
An unconstraint (extended) Robbins-Monro algorithm can be derived, provided
 the function F satisfies a sub-multiplicative control property, in which
 
\begin_inset Formula $c>0$
\end_inset

 is a real parameter and 
\begin_inset Formula $\tilde{F}$
\end_inset

 a function from 
\begin_inset Formula $\RR^{d}$
\end_inset

 to 
\begin_inset Formula $\RR_{+}$
\end_inset

, such that, namely: 
\begin_inset Formula 
\begin{eqnarray*}
\left\{ \begin{array}{l}
\forall x,y\in\RR^{d},\quad|F(x)|<\tilde{F}(x)\ and\ \tilde{F}(x+y)\leq C(1+\tilde{F}(x))^{c}(1+\tilde{F}(y))^{c}\\
\EE\left[|X|^{2(a-1)}\tilde{F}(X)^{4c}\right]<+\infty
\end{array}\right.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
We give a brief description of the hypotheses necessary for the following
 theorem.
 For a complete definition, we kindly refer to the author's article.
\end_layout

\begin_layout Itemize
\begin_inset Formula $(H1)$
\end_inset

 log-concavity of 
\begin_inset Formula $p_{\theta}$
\end_inset

, and conditions on limits for 
\begin_inset Formula $p_{\theta}$
\end_inset

 and 
\begin_inset Formula $\frac{p_{\theta}}{p_{\theta/2}^{2}}$
\end_inset

 for 
\begin_inset Formula $|\theta$
\end_inset

| going to infinity (article p.2).
\end_layout

\begin_layout Itemize
\begin_inset Formula $(Ha)$
\end_inset

 existence of an 
\begin_inset Formula $a\in[1,2]$
\end_inset

 satisfying certain growth boundary conditions and log-convexity for density
 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $(Hc)$
\end_inset

 existence of an function 
\begin_inset Formula $\widetilde{F}$
\end_inset

 majoring 
\begin_inset Formula $|F|$
\end_inset

 and satisfying certain growth and finite expectation conditions.
\end_layout

\begin_layout Theorem
: Suppose X and F satisfy 
\begin_inset Formula $(H1)$
\end_inset

, 
\begin_inset Formula $(Ha)$
\end_inset

 and 
\begin_inset Formula $(Hc)$
\end_inset

 for some parameters 
\begin_inset Formula $a\in(0,2]$
\end_inset

, 
\begin_inset Formula $b\in(0,a)$
\end_inset

 and 
\begin_inset Formula $\lambda>0$
\end_inset

, and that the step sequence 
\begin_inset Formula $(\gamma_{n})_{n\geq1}$
\end_inset

 satisfies the usual decreasing step assumption 
\begin_inset Formula 
\begin{equation}
\sum\limits _{\substack{n\geq1}
}^{}{\gamma_{n}}=+\infty\quad and\quad\sum\limits _{\substack{n\geq1}
}^{}{\gamma_{n}^{2}}<+\infty
\end{equation}

\end_inset

Then the recursive procedure defined by 
\begin_inset Formula 
\begin{equation}
\theta_{n}=\theta_{n-1}-\gamma_{n+1}H(\theta_{n},X_{n+1}),\quad n\geq1
\end{equation}

\end_inset

where 
\begin_inset Formula $(X_{n})_{n\geq1}$
\end_inset

 be an 
\begin_inset Formula $i.i.d.$
\end_inset

 sequence with the same distribution as X and 
\begin_inset Formula 
\begin{equation}
H(\theta,x)=\frac{F^{2}(x-\theta)}{1+\tilde{F}(-\theta)^{2c}}e^{-2\delta|\theta|^{a}}\frac{p^{2}(x-\theta)}{p(x)p(x-2\theta)}\frac{\bigtriangledown p(x-2\theta)}{p(x-2\theta)},
\end{equation}

\end_inset

a.s.
 converges toward an Argmin V
\begin_inset Formula $-valued\ (square\ integrable)$
\end_inset

 random variable 
\begin_inset Formula $\theta^{*}$
\end_inset


\end_layout

\begin_layout Chapter
Importance Simpling on finite-dimensional setting
\end_layout

\begin_layout Standard
In this section we will consider the case of a gaussian distribution to
 value European payoffs using Monte-Carlo method.
 We will study the variance reduction brought by unconstrained Robbins-Monro
 method, with a benchmark of our results by the Newton-Raphson method.
\end_layout

\begin_layout Section
(Newton Raphson)
\end_layout

\begin_layout Standard
As using the framework defined before in the particular case where 
\begin_inset Formula $G\backsim\mathcal{N}(0,I_{d})$
\end_inset

, and 
\begin_inset Formula $\theta\in\RR^{d}$
\end_inset

, (1) gives us: 
\begin_inset Formula 
\[
\EE[F(G)]=\EE\left[F(G+\theta)e^{-\theta.G-\frac{|\theta|^{2}}{2}}\right]
\]

\end_inset

The variance of our new quantity is : 
\begin_inset Formula 
\begin{eqnarray*}
 &  & \forall\theta\in\RR^{d},\quad Var\left(F(G+\theta)e^{-\theta.G-\frac{|\theta|^{2}}{2}}\right)=v(\theta)-\EE[F(G)]^{2}\\
 &  & where\ v(\theta)=\EE\left[F^{2}(G)e^{-\theta.G-\frac{|\theta|^{2}}{2}}\right]
\end{eqnarray*}

\end_inset

We can prove that if our payoff satisfy the condition 
\begin_inset Formula $\PP(F^{2}(G)>0)>0$
\end_inset

, the 
\begin_inset Formula $v(\theta)$
\end_inset

 defined before verify he following relation: 
\begin_inset Formula 
\[
\lim_{|\theta|\to+\infty}v(\theta)=+\infty
\]

\end_inset

Finaly, if 
\begin_inset Formula $\forall R>0$
\end_inset

, 
\begin_inset Formula $\EE\left[|G|^{2}F^{2}(G)e^{R|G|}\right]<+\infty$
\end_inset

 concider 
\begin_inset Formula $\partial v$
\end_inset

 and 
\begin_inset Formula $\partial^{2}v$
\end_inset

 defined as follows: 
\begin_inset Formula 
\begin{eqnarray*}
 &  & \partial v=\EE\left[F^{2}(G)(\theta-G)e^{-\theta.G-\frac{|\theta|^{2}}{2}}\right]\\
 &  & \partial^{2}v=\EE\left[F^{2}(G)\{I_{d}+(\theta-G)(\theta-G)^{T}\}e^{-\theta.G-\frac{|\theta|^{2}}{2}}\right]
\end{eqnarray*}

\end_inset

We can prove that 
\begin_inset Formula $\exists!\ \theta^{*}$
\end_inset

 difined by: 
\begin_inset Formula 
\[
\theta^{*}=Argmin\ v
\]

\end_inset


\end_layout

\begin_layout Section
Framework of study
\end_layout

\begin_layout Standard
We put ourselves under the Black-Scholes model for a d-dimensional underlying
 
\begin_inset Formula $(S_{t})\in\RR^{d}$
\end_inset

.
 Under the risk-neutral probability 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 we have the following dynamics 
\begin_inset Formula 
\[
\frac{dS_{t}}{S_{t}}=rdt+\sigma dW_{t}\quad i.e.\;\forall t\geq s,\;S_{t}=S_{s}e^{(r-\sigma^{2}/2)(t-s)+\sigma(W_{t}-W_{s})}
\]

\end_inset

where 
\begin_inset Formula $r$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 are the constant risk-free rate and volatility, and 
\begin_inset Formula $W_{t}$
\end_inset

 is a centered d-dimensional brownian motion of symetric positive correlation
 matrix 
\begin_inset Formula $\Gamma\in M_{d,d}$
\end_inset

.
\end_layout

\begin_layout Standard
Under this framework, we will compute the value 
\begin_inset Formula $C_{t}$
\end_inset

 of European payoffs 
\begin_inset Formula $\bar{F}(S_{T})$
\end_inset

 (depending only of the underlying 
\begin_inset Formula $S$
\end_inset

 at maturity
\begin_inset Formula $T$
\end_inset

): 
\begin_inset Formula $C_{t}(t,S)=\EE^{\mathbb{Q}}[\bar{F}(S_{T})|S_{t}=S]$
\end_inset

.
\end_layout

\begin_layout Standard
We note 
\begin_inset Formula $G\in\RR^{d}$
\end_inset

 a d-dimensionnal independant gaussian vector.
 If we note 
\begin_inset Formula $\sqrt{\Gamma}$
\end_inset

 the matrix obtained by Cholesky decomposition of 
\begin_inset Formula $\Gamma$
\end_inset

 (which exists well), we have 
\begin_inset Formula $W_{t}=\sqrt{t}\sqrt{\Gamma}G$
\end_inset

.
\end_layout

\begin_layout Standard
We can then define the payoff function depending on G and time 0, 
\begin_inset Formula $F(G)=\bar{F}(S_{T})=\bar{F}(S_{0}e^{(r-\sigma^{2}/2)T+\sigma W_{T}}\sim\bar{F}(S_{0}e^{(r-\sigma^{2}/2)T+\sigma\sqrt{T}\Gamma.G})$
\end_inset

.
\end_layout

\begin_layout Standard
We are therefore able to use the procedure of Theorem 1 to estimate 
\begin_inset Formula $\theta*$
\end_inset

, using a function 
\begin_inset Formula $H$
\end_inset

 as defined in Theorem 2.
 For a gaussian density 
\begin_inset Formula $p$
\end_inset

, we can use parameters 
\begin_inset Formula $a=2,\;\delta=\frac{1}{2},\;c=\frac{1}{2}$
\end_inset

 for Theorem 2., and we have also 
\begin_inset Formula $\frac{\nabla p(x)}{p(x)}=-x$
\end_inset

.
 We have therefore 
\begin_inset Formula $\frac{p^{2}(x-\theta)}{p(x)p(x-2\theta)}\frac{\bigtriangledown p(x-2\theta)}{p(x-2\theta)}=e^{|\theta^{2}|}(2\theta$
\end_inset

-x), and the formula from Theorem 2 simplifies to :
\begin_inset Formula 
\[
H(\theta,G)=\frac{F^{2}(G-\theta)}{(1+\widetilde{F}(-\theta)}(2\theta-X)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $F$
\end_inset

 and 
\begin_inset Formula $\widetilde{F}$
\end_inset

 are depending of the payoff.
\end_layout

\begin_layout Section
Application to specific European payoffs
\end_layout

\begin_layout Standard
We will study two payoffs in this section : a call option and a best-of
 call option.
\end_layout

\begin_layout Subsubsection
Call option
\end_layout

\begin_layout Standard
We consider a call option on a single asset, of strike 
\begin_inset Formula $K$
\end_inset

 and maturity 
\begin_inset Formula $T$
\end_inset

.
 We have the following payoff : 
\begin_inset Formula 
\[
F(G)=\bar{F}(S_{T})=(S_{T}-K)^{+}=(S_{0}e^{(r-\sigma^{2}/2)T+\sigma\sqrt{T}G}-K)^{+}
\]

\end_inset


\end_layout

\begin_layout Standard
We need 
\begin_inset Formula $\widetilde{F}_{Call}$
\end_inset

 to verify hypothesis 
\begin_inset Formula $(Hc)$
\end_inset

 : a relevant choice is 
\begin_inset Formula 
\[
\widetilde{F}_{Call}(\theta)=S_{0}e^{(r-\sigma^{2}/2)T+\sigma\sqrt{T}\theta}
\]

\end_inset

.
\end_layout

\begin_layout Subsubsection
Best-of Call option
\end_layout

\begin_layout Standard
We consider a best-of call option on two correlated assets 
\begin_inset Formula $S^{1}$
\end_inset

 and 
\begin_inset Formula $S^{2}$
\end_inset

, of strike 
\begin_inset Formula $K$
\end_inset

 and maturity 
\begin_inset Formula $T$
\end_inset

.
 We have 
\begin_inset Formula $\Gamma=\begin{pmatrix}\sigma_{1} & \rho\sigma_{1}\sigma_{2}\\
\rho\sigma_{1}\sigma_{2} & \sigma_{2}
\end{pmatrix}$
\end_inset

 The payoff is as follows :
\begin_inset Formula 
\[
F(G)=(max(S_{T}^{1},S_{T}^{2})-K)^{+}=(max(S_{0}^{1}e^{(r-\sigma_{1}^{2}/2)T+\sqrt{T}(\Gamma.G)_{1}},S_{0}^{2}e^{(r-\sigma_{2}^{2}/2)T+\sqrt{T}(\Gamma.G)_{2}})-K)^{+}
\]

\end_inset

where 
\begin_inset Formula $V_{i}$
\end_inset

 refers to the i-th component of vector V.
\end_layout

\begin_layout Standard
We can therefore choose for 
\begin_inset Formula $\widetilde{F}_{BestOfCall}$
\end_inset

 (with a 2-dimensional 
\begin_inset Formula $\theta$
\end_inset

): 
\begin_inset Formula 
\[
\widetilde{F}_{BestOfCall}(\theta)=max(S_{0}^{1}e^{(r-\sigma_{1}^{2}/2)T+\sqrt{T}(\Gamma.\theta)_{1}},S_{0}^{2}e^{(r-\sigma_{2}^{2}/2)T+\sqrt{T}(\Gamma.\theta)_{2}})
\]

\end_inset


\end_layout

\begin_layout Section
Numerical results
\end_layout

\begin_layout Chapter
Adaptive variance reduction for diffusions
\end_layout

\begin_layout Standard
We will then study the method in a more general context extended to stochastic
 processes (instead of random gaussian variables).
 This will allow us to consider the approach for path-dependant payoffs
 like barrier options.
 We have therefore to consider time-dependant, possibly stochastic shift
 processes 
\begin_inset Formula $\Theta$
\end_inset

(instead of constant shifts like in previous section).
\end_layout

\begin_layout Section
Framework and preliminaries
\end_layout

\begin_layout Subsection
Derivation of the shifting problem
\end_layout

\begin_layout Standard
We consider a d-dimensional Ito process 
\begin_inset Formula $X=(X_{t})_{t\in[0,T]}$
\end_inset

 solution to the stochastic differential equation (SDE): 
\end_layout

\begin_layout Standard
\begin_inset Formula $dX_{t}=b(t,X^{t})dt+\sigma(t,X^{t})dW_{t},\quad X_{0}=x\in\RR^{d}$
\end_inset

 (
\begin_inset Formula $E_{b,\sigma,W}$
\end_inset

) 
\end_layout

\begin_layout Standard
where 
\begin_inset Formula $W=(W_{t})_{t\in[0,T]}$
\end_inset

 is a q-dimensional brownian motion, 
\begin_inset Formula $X^{t}=(X_{t\wedge s})_{s\in[0,T]}$
\end_inset

, 
\begin_inset Formula $b:[0,T]x(C([0,T],\RR^{d}))\rightarrow\RR^{d}$
\end_inset

and 
\begin_inset Formula $\sigma:[0,T]x(C([0,T],\RR^{d}))\rightarrow M(d,q)$
\end_inset

 are measurable with respect to the canonical 
\begin_inset Formula $\sigma$
\end_inset

-field.
\end_layout

\begin_layout Standard
The aim is again to compute 
\begin_inset Formula $\EE[F(X)]$
\end_inset

 with a minimal variance.
 In this functional setting, Girsanov's theorem plays the role of the invariance
 of Lebesgue's measure by translation.
 The translation process considered is of the form 
\begin_inset Formula $\Theta(t,X^{t})$
\end_inset

 where 
\begin_inset Formula $\Theta(t,X^{t})=\varphi(t,\xi^{t})\theta_{t}$
\end_inset

 with 
\begin_inset Formula $\xi\in C([0,T],\RR^{d})$
\end_inset

 and 
\begin_inset Formula $\varphi:[0,T]x(C([0,T],\RR^{d}))\rightarrow M(q,p)$
\end_inset

.
\end_layout

\begin_layout Standard
It is possible to show that with hypotheses similar to Lipschitz for the
 functions 
\begin_inset Formula $b$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

, the SDE admits a unique solution 
\begin_inset Formula $X_{t}$
\end_inset

.
 It is also possible to show that, with the notations 
\begin_inset Formula 
\[
\Theta_{t}=\Theta(t,X^{t}),\quad\Theta_{t}^{(\theta)}=\Theta(t,X^{(\theta),t}),\quad\Theta_{t}^{(-\theta)}=\Theta(t,X^{(-\theta),t})
\]

\end_inset

 where 
\begin_inset Formula $X^{\pm\theta}$
\end_inset

 represents the solution to (
\begin_inset Formula $E_{b,\sigma\pm\sigma\Theta,\sigma,W}$
\end_inset

), that 
\begin_inset Formula 
\[
\EE[F(X)]=\EE\left[F(X^{(\theta)})^{2}e^{-\int_{0}^{T}<\Theta_{s}^{(\theta)},dW_{s}>-\frac{1}{2}||\Theta^{(\theta)}||_{L_{T,q}^{2}}^{2}}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
We are looking for 
\begin_inset Formula $\Theta^{*}=\underset{\theta\in L_{T,p}^{2}}{min}V(\theta)$
\end_inset

 with 
\begin_inset Formula $V(\theta)=\EE\left[F^{2}(X^{(\theta)})e^{-2\int_{0}^{T}<\Theta_{s}^{(\theta)},dW_{s}>-\frac{1}{2}||\Theta^{(\theta)}||_{L_{T,q}^{2}}^{2}}\right]$
\end_inset

.
 By a result equivalent to the change of probability in this setting, we
 can obtain 
\begin_inset Formula 
\[
V(\theta)=\EE\left[F^{2}(X)e^{-2\int_{0}^{T}<\Theta_{s},dW_{s}>-\frac{1}{2}||\Theta||_{L_{T,q}^{2}}^{2}}\right]
\]

\end_inset


\end_layout

\begin_layout Subsection
Projection on polynomials basis
\end_layout

\begin_layout Standard
The searched process 
\begin_inset Formula $\Theta^{*}$
\end_inset

 is infinite-dimensional in theory.
 In practice the only way to implement this algorithm is to restrict the
 problem on some finite-dimensional subspace.
 We will consider different polynomials basis of the space
\begin_inset Formula $L^{2}$
\end_inset

 and will approach 
\begin_inset Formula $\Theta^{*}$
\end_inset

 by 
\begin_inset Formula $\bar{\Theta}^{*}$
\end_inset

the solution of the minimisation problem of 
\begin_inset Formula $V$
\end_inset

 , projected on these polynomial basis.
 We can now present the equivalent of Theorem 2.
 on this setting.
\end_layout

\begin_layout Theorem
:Suppose that Assumption (3.23) and 
\begin_inset Formula $(H_{b,\sigma})$
\end_inset

 hold.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\varphi$
\end_inset

 be a bounded Borel 
\begin_inset Formula $M(q,p)$
\end_inset

-valued function (with 
\begin_inset Formula $p\geq1$
\end_inset

) defined on 
\begin_inset Formula $[0,T]\times C([0,T],R^{d})$
\end_inset

, and let F be a functional F satisfying
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\forall x\in C([0,T],R^{d}),\ |F(x)|\leq C_{F}F(1+||x||_{\infty}^{\lambda})
\end{equation}

\end_inset

for some positive exponent 
\begin_inset Formula $\lambda>0$
\end_inset

 (then 
\begin_inset Formula $F(X)\in L^{r}(\PP)$
\end_inset

 for every 
\begin_inset Formula $r>0$
\end_inset

).
 Let E be a finite dimensional subspace of 
\begin_inset Formula $L_{T,p}^{2}$
\end_inset

 spanned by an orthonormal basis 
\begin_inset Formula $(e_{1},...,e_{m})$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\eta>0$
\end_inset

.
 We define the algorithm by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\theta_{n}=\theta_{n-1}-\gamma_{n+1}H_{\lambda,\eta}(\theta_{n},X^{(-\theta_{n})},W^{n+1}),\quad n\geq1
\end{equation}

\end_inset

where 
\begin_inset Formula $\gamma=(\gamma_{n})_{n\geq1}$
\end_inset

 satisfies the same property as in Theorem 1., 
\begin_inset Formula $(W^{(n)})_{n\geq1}$
\end_inset

is a sequence of independant Brownian motions for which 
\begin_inset Formula $X^{(-\theta_{n})}$
\end_inset

 is a strong solution to (
\begin_inset Formula $E_{b,\sigma\pm\sigma\Theta,\sigma,W^{(n+1)}}$
\end_inset

), and for every standard brownian motion W, every adapted process 
\begin_inset Formula $\xi$
\end_inset

,
\begin_inset Formula 
\[
<H_{\lambda,\eta}(\theta,\xi,W),e_{i}>_{L_{T,p}^{2}}=\Psi_{\lambda,\eta}(\theta,\xi)F^{2}(\xi)e^{||\Theta(.,\xi)||_{L_{T,q}^{2}}}(2<\Theta(.,\xi),\varphi(.,\xi)e_{i}>_{L_{T,q}^{2}}-\int_{0}^{T}<\varphi(s,\xi^{s})e_{i}(s),dW_{s}>)
\]

\end_inset

 where for 
\begin_inset Formula $\eta>0$
\end_inset

,
\begin_inset Formula 
\begin{eqnarray*}
\Psi_{\lambda,\eta}(\theta,\xi) & = & \begin{cases}
\mbox{\ensuremath{\frac{e^{-||\varphi||_{\infty}||\theta||_{L^{2}}}}{1+||\varphi(.,\xi)\theta||_{L^{2}}^{2\lambda+\eta}}}} & if\;\sigma\;bounded\\
e^{-(||\varphi||_{\infty}+\eta)||\theta||_{L^{2}}} & if\;\sigma\;unbounded
\end{cases}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Then the recursive sequence (
\begin_inset Formula $\theta_{n})_{n\geq1}$
\end_inset

 converges to a 
\begin_inset Formula $L^{2}$
\end_inset

random variable 
\begin_inset Formula $\theta^{*}$
\end_inset

.
\end_layout

\begin_layout Subsection
Simplification of our problem
\end_layout

\begin_layout Standard
For sake of simplicity, we will consider in our case 
\begin_inset Formula $\varphi\equiv Id$
\end_inset

, which gives us for 
\begin_inset Formula $\Theta$
\end_inset

a deterministic function 
\begin_inset Formula $\Theta(t,X^{(\pm\theta),t})=\theta_{t}$
\end_inset

.
 We will also consider 
\begin_inset Formula $\sigma$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 depending only of the current value of 
\begin_inset Formula $X$
\end_inset

 i.e.
\end_layout

\begin_layout Standard
\begin_inset Formula $\sigma(t,X^{t})=\sigma(X_{t})$
\end_inset

 and 
\begin_inset Formula $b(t,X^{t})=b(X_{t})$
\end_inset

.
\end_layout

\begin_layout Standard
We have therefore, similar to section 2,
\begin_inset Formula $\nabla V(\theta)=\EE[H(\theta,X^{(-\theta)},W)]$
\end_inset

, and so in our case for 
\begin_inset Formula $\psi\in L_{T,p}^{2}$
\end_inset

 
\begin_inset Formula 
\[
<\nabla V(\theta),\psi>_{L_{T,p}^{2}}=\EE[F^{2}(X^{(-\theta)})e^{||\theta||_{L^{2}}^{2}}(2<\theta,\psi>_{L_{T,p}^{2}}-\int_{0}^{T}<\varphi_{s},dW_{s}>]
\]

\end_inset


\end_layout

\begin_layout Standard
For an orthonormal basis 
\begin_inset Formula $(e_{1},...,e_{m})$
\end_inset

 of 
\begin_inset Formula $L_{T,p}^{2}$
\end_inset

, we can write 
\begin_inset Formula $\theta_{t}={\displaystyle \sum_{i=1}^{m}\theta_{i}e_{i}}$
\end_inset

, with (
\begin_inset Formula $\theta_{1},\ldots,\theta_{m})\in\RR^{m}$
\end_inset

.
 We have there also an explicit formula for the restriction of 
\begin_inset Formula $H$
\end_inset

 on this basis: 
\begin_inset Formula 
\[
<H(\theta,X^{(-\theta)},W),e_{i}>_{L_{T,p}^{2}}=F^{2}(X^{(-\theta)})e^{||\theta||_{L^{2}}^{2}}(2<\theta,e_{i}>_{L_{T,p}^{2}}-\int_{0}^{T}<e_{i}(s),dW_{s}>_{L_{T,p}^{2}}]
\]

\end_inset

 which gives us with the recursive relation of Theorem 3.
 an implementable methodology for the algorithm.
\end_layout

\begin_layout Section
Application to path-dependant payoffs
\end_layout

\begin_layout Subsection
Polynomials basis used 
\end_layout

\begin_layout Subsubsection
Legendre polynomial basis
\end_layout

\begin_layout Standard
Legendre basis used is a polynomial basis of 
\begin_inset Formula $L^{2}([0,1],\RR)$
\end_inset

, composed of the shifted Legendre polynomials 
\begin_inset Formula $\tilde{P}_{n}(t)$
\end_inset

defined by: 
\begin_inset Formula 
\[
\forall n>0,\ \forall t\in[0,1],\ \tilde{P}_{n}(t)=P_{n}(2t-1)\quad where\quad P_{n}(t)=\frac{1}{2^{n}n!}\frac{d^{n}}{dt^{n}}\left((t^{2}-1)^{n}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Haar polynomial basis
\end_layout

\begin_layout Standard
Haar basis used is a polynomial basis of 
\begin_inset Formula $L^{2}([0,1],\RR)$
\end_inset

, defined by 
\begin_inset Formula 
\[
\forall n\geq0,\forall k=0,...,2^{n}-1,\forall t\in[0,1],\quad\psi_{n,k}=2^{\frac{n}{2}}\psi(2^{n}t-k)
\]

\end_inset

where 
\begin_inset Formula $\psi(t)=\begin{cases}
1 & if\;t\in[0,\frac{1}{2})\\
-1 & if\;t\in[\frac{1}{2},1)\\
0 & otherwise
\end{cases}$
\end_inset

.
\end_layout

\begin_layout Subsection
Payoff considered :Barrier option (Down & In Call)
\end_layout

\begin_layout Standard
We consider a process 
\begin_inset Formula $(S_{t})_{t\geq0}$
\end_inset

 solution of the following diffusion 
\begin_inset Formula 
\[
dS_{t}=rdt+\sigma dW_{t},\quad S_{0}=s_{0}\in\RR,
\]

\end_inset

A Down 
\begin_inset Formula $\&$
\end_inset

 In Call option of strike K and barrier L is a Call of strike K which is
 activated when the underlying X moves down and hits the barrier L at a
 point of life of the product.
 The payoff of such a European option is defined by: 
\begin_inset Formula 
\[
F(S_{T})=\left(S_{T}-K\right)^{+}\mathds{1}_{\left\{ \min\limits _{\substack{0\leq t\leq T}
}S_{t}\leq L\right\} }
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\tilde{F}$
\end_inset

 ?
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
- Call for benchmark
\end_layout

\begin_layout Standard
-Graphe of the variance reduction, depending on the number of steps, the
 number of theta, the types of polynom
\end_layout

\begin_layout Standard
-Graphe of the thetas.
\end_layout

\begin_layout Chapter*
Conclusion
\end_layout

\end_body
\end_document
